# AnyLLM-to-VLM ğŸš€

Turn any text-only LLM into a Vision-Language Model through efficient training.

## Features
- ğŸ”Œ Plug-and-play adapter for existing LLMs
- ğŸ¯ Minimal training required  
- ğŸ“· Support for CLIP and other vision encoders
- ğŸ¦™ Compatible with popular LLMs (Qwen, LLaMA, etc.)
