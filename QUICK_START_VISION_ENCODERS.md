# è§†è§‰ç¼–ç å™¨å¿«é€Ÿä½¿ç”¨æŒ‡å—

## å½“å‰æ”¯æŒçš„ç¼–ç å™¨

- âœ… **CLIP** (å·²å®ç°ï¼Œé»˜è®¤)
- ğŸ“ **ViT** (ç¤ºä¾‹ä»£ç å·²æä¾›ï¼Œéœ€è¦æµ‹è¯•)

## ä½¿ç”¨æ–¹æ³•

### 1. ä½¿ç”¨CLIPï¼ˆé»˜è®¤ï¼‰

åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼š

```yaml
model:
  vision_model_type: "clip"
  vision_model_path: "../multimodal-vlm/models/clip-vit-base-patch16"
  freeze_vision_encoder: true
  vision_layers_to_unfreeze: 0
```

### 2. åˆ‡æ¢åˆ°å…¶ä»–ç¼–ç å™¨

åªéœ€ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ `vision_model_type` å’Œ `vision_model_path`ï¼š

```yaml
model:
  vision_model_type: "vit"  # æ”¹ä¸ºä½ æƒ³è¦çš„ç¼–ç å™¨ç±»å‹
  vision_model_path: "../multimodal-vlm/models/vit-base-patch16-224"
  freeze_vision_encoder: true
  vision_layers_to_unfreeze: 0
```

### 3. æ·»åŠ æ–°ç¼–ç å™¨ï¼ˆ3æ­¥ï¼‰

#### æ­¥éª¤1: åˆ›å»ºç¼–ç å™¨æ–‡ä»¶

åˆ›å»º `model/vision_encoders/your_encoder.py`ï¼Œç»§æ‰¿ `BaseVisionEncoder`ï¼š

```python
from .base import BaseVisionEncoder

class YourVisionEncoder(BaseVisionEncoder):
    def load_model(self):
        # åŠ è½½ä½ çš„æ¨¡å‹
        pass
    
    def load_processor(self):
        # åŠ è½½å¤„ç†å™¨
        pass
    
    def get_image_embeddings(self, pixel_values):
        # è¿”å› [batch_size, num_patches, hidden_size]
        pass
    
    @property
    def hidden_size(self):
        # è¿”å›éšè—å±‚ç»´åº¦
        pass
```

#### æ­¥éª¤2: æ³¨å†Œç¼–ç å™¨

åœ¨ `model/vision_encoders/factory.py` æœ«å°¾æ·»åŠ ï¼š

```python
from .your_encoder import YourVisionEncoder
VisionEncoderFactory.register('your_encoder', YourVisionEncoder)
```

#### æ­¥éª¤3: åœ¨é…ç½®ä¸­ä½¿ç”¨

```yaml
model:
  vision_model_type: "your_encoder"
  vision_model_path: "path/to/your/model"
```

## æ¶æ„ä¼˜åŠ¿

1. **è§£è€¦è®¾è®¡**: è§†è§‰ç¼–ç å™¨ä¸ä¸»æ¨¡å‹è§£è€¦ï¼Œæ˜“äºæ›¿æ¢
2. **ç»Ÿä¸€æ¥å£**: æ‰€æœ‰ç¼–ç å™¨ä½¿ç”¨ç›¸åŒçš„æ¥å£ï¼Œä¸»æ¨¡å‹ä»£ç æ— éœ€ä¿®æ”¹
3. **æ˜“äºæ‰©å±•**: åªéœ€å®ç°åŸºç±»æ–¹æ³•ï¼Œæ— éœ€ä¿®æ”¹æ ¸å¿ƒä»£ç 
4. **å‘åå…¼å®¹**: ç°æœ‰CLIPä»£ç å®Œå…¨å…¼å®¹

## æŸ¥çœ‹å·²æ³¨å†Œçš„ç¼–ç å™¨

```python
from model.vision_encoders import VisionEncoderFactory

print(VisionEncoderFactory.list_encoders())
# è¾“å‡º: ['clip']
```

## å¸¸è§ç¼–ç å™¨ç¤ºä¾‹

### DINOv2

```python
# model/vision_encoders/dinov2_encoder.py
from transformers import Dinov2Model, AutoImageProcessor
from .base import BaseVisionEncoder

class DINOv2VisionEncoder(BaseVisionEncoder):
    def load_model(self):
        return Dinov2Model.from_pretrained(self.model_path)
    
    def load_processor(self):
        return AutoImageProcessor.from_pretrained(self.model_path)
    
    def get_image_embeddings(self, pixel_values):
        outputs = self.model(pixel_values=pixel_values)
        return outputs.last_hidden_state[:, 1:, :]  # å»æ‰CLS token
    
    @property
    def hidden_size(self):
        return self.model.config.hidden_size
```

### BLIP

```python
# model/vision_encoders/blip_encoder.py
from transformers import BlipModel, BlipProcessor
from .base import BaseVisionEncoder

class BLIPVisionEncoder(BaseVisionEncoder):
    def load_model(self):
        return BlipModel.from_pretrained(self.model_path)
    
    def load_processor(self):
        return BlipProcessor.from_pretrained(self.model_path)
    
    def get_image_embeddings(self, pixel_values):
        outputs = self.model.get_image_features(pixel_values=pixel_values)
        # æ ¹æ®BLIPçš„å®é™…è¾“å‡ºæ ¼å¼è°ƒæ•´
        return outputs
```

## æ³¨æ„äº‹é¡¹

1. **è¾“å‡ºæ ¼å¼**: `get_image_embeddings` å¿…é¡»è¿”å› `[batch_size, num_patches, hidden_size]`
2. **CLS Token**: å¤§å¤šæ•°ViTç±»æ¨¡å‹éœ€è¦å»æ‰ç¬¬ä¸€ä¸ªCLS token
3. **éšè—å±‚ç»´åº¦**: ç¡®ä¿ `hidden_size` æ­£ç¡®ï¼Œå½±å“æŠ•å½±å±‚ç»´åº¦
4. **å¤„ç†å™¨å…¼å®¹**: ç¡®ä¿è®­ç»ƒå’Œæ¨ç†ä½¿ç”¨ç›¸åŒçš„å¤„ç†å™¨

## æµ‹è¯•æ–°ç¼–ç å™¨

```python
from model.vision_encoders import VisionEncoderFactory

# åˆ›å»ºå¹¶æµ‹è¯•
encoder = VisionEncoderFactory.create(
    encoder_type='your_encoder',
    model_path='path/to/model',
    freeze=True
)

# æµ‹è¯•å¤„ç†å›¾åƒ
from PIL import Image
image = Image.open('test.jpg').convert('RGB')
pixel_values = encoder.processor(image, return_tensors='pt')['pixel_values']
embeddings = encoder.get_image_embeddings(pixel_values)
print(f"åµŒå…¥å½¢çŠ¶: {embeddings.shape}")
```

## æ›´å¤šä¿¡æ¯

è¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒ: `README_VISION_ENCODERS.md`
